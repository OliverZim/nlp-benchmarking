# A script for benchmarking deep learning best practices

This script can be used to benchmark common best practices in deep learning (e.g. model-compilation and mixed-precision-training) and evaluate the actual impact of these methods on training speed. This work is based on the [NLP research template](https://github.com/konstantinjdobler/nlp-research-template).

For example results take a look at these reports:
* [basic report with wandb](https://api.wandb.ai/links/nlp_benchmarks/61y8sxqu)